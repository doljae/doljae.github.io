---
slug: 355
title: "LLM 서비스 설계와 최적화 - 비용은 낮추고 성능은 극대화하는 AI 서비스 구축과 운영 가이드"
authors: seokjae
tags: ["ai-agent", "bedrock", "chatgpt", "llm-서비스-설계와-최적화", "나는리뷰어다", "비용", "토큰"]
enableComments: true
keywords: ["ai-agent", "bedrock", "chatgpt", "llm-서비스-설계와-최적화", "나는리뷰어다", "비용", "토큰"]
date: 2025-06-03T17:19:05+09:00
---

> 원문: https://doljae.tistory.com/355

**한빛미디어 서평단 &lt;나는리뷰어다&gt; 활동을 위해서 책을 협찬 받아 작성된 서평입니다.**

![](https://blog.kakaocdn.net/dn/bhq4JJ/btsOovjnvPr/1NLj2xOjleKoAok9olqE90/img.jpg)

23년에 ChatGPT가 LLM 모델 전쟁의 서막을 열었고 24년에 여러 AI 도구가 출시되었다면 25년에는 AI를 서비스에 녹이는 것이 주된 이야깃거리 중 하나다. 이전에는 ChatGPT를 잘 쓰는 법이 관심사였다면, 지금은 어떻게 ChatGPT와 같은 AI 서비스를 만들 수 있을까에 더 관심이 모이고 있는 것 같다. 자체 개발 LLM이 없더라도 Ollama 등 오픈소스 LLM으로 모델은 확보할 수 있다. 하지만 이 모델을 가지고 실제 서비스를 개발, 운영하는 것은 조금 다른 이야기이다.

<!-- truncate -->

전통적인 애플리케이션에서의 문제 해결 방법은 특정 상황에만 대응할 수 있는 코드, 함수, API를 만드는 것이다. 즉 어떤 목적을 달성하기 위한 프로그램이기에 유연하지 못 하지만 굉장히 굉장히 빠르고 결정적인 결과를 만들어 내고 이는 개발자가 프로그램의 결과를 예상하고 이에 대응할 수 있다는 장점이 있다. AI 서비스는 이와 정반대의 특징을 가진다. 성능이 검증된 일정 크기의 LLM 모델을 사용하는 것만으로도 여러 가지 상황에 대응하고 다양한 종류의 문제를 풀 수 있다. 하지만 개발자는 LLM이 만들어내는 결과를 예상하는 것이 거의 불가능하다. 심지어 같은 입력에 대해서도 LLM 모델은 다른 결과를 내는데 이것을 제어하기 위해 LLM에 제공할 입력 값인 프롬프트를 튜닝하는 것이 최선이다. 뿐만 아니라 AI 모델은 리소스도 많이 소모한다. 학습이 완료된 모델을 사용하기만 하더라도 일반적인 애플리케이션에서 필요한 인프라 자원보다 훨씬 더 여유로운 RAM과 저장소 용량이 필요하다. 만일 클라우드 서비스로 AI 모델을 사용한다면 생성되는 답변의 길이에 비례해서 운영 비용이 증가한다. 심지어 답변이 길 수록 응답 속도마저 느리다.

이처럼 LLM 모델을 활용한 AI 서비스는 전통적인 웹 서비스와 비교했을 때 운영 관점에서 새롭게 고려해야 할 부분이 많다. ChatGPT를 쓰는 건 쉽지만 ChatGPT를 만드는 것은 전혀 다르다. 이 책은 LLM 서비스를 구축하고 운영할 때 고려해야 할 여러 가지 부분을 친절하게 짚어준다. 잘 그려진 시스템 구조도와 함께 AI 서비스를 개발할 때 겪게 되는 여러 가지 문제와 이에 대한 해결책 혹은 타협책을 제시한다.

서비스 개발자 입장에서 읽기 쉽게 작성되었다는 점도 좋았다. 내가 읽었던 AI, LLM 관련 책은 대부분 관련 지식이 전무하거나 많이 부족한 초심자를 위함이거나, 혹은 숙련된 전문가를 위한 책이었는데 이 책은 초심자와 전문가 사이에 있는 사람들이 읽었을 때 충분히 책 제목에서 기대하는 그런 내용을 얻을 수 있지 않나 싶다.

최근에 국내에 열린 AWS Summit에서도 Bedrock이라는 AI 에이전트 서비스를 굉장히 많이 홍보했었는데. 세션에서 나온 AI 서비스의 구조와 이 책에서도 몇 가지 유사한 점을 발견할 수 있었다. 이런 점을 보면 이젠 AI를 활용한 서비스의 시스템 구조도 어느 정도 정형화가 되지 않았나 싶다. LLM 모델을 활용해 여러 가지 상황에 유연하게 대응하면서도, 전통적인 웹 서비스처럼 속도와 비용 효율도 잡아야 한다면 이 책의 내용에서 뭔가 건져갈 수 있지 않을까 싶다.
